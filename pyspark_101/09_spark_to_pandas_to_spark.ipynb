{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1597360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/13 21:51:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "# start SparkSession with Hive support enabled\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"SparkSession\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68744278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loading CSV data as Spark df\n",
    "flights_df = spark.read.option('header', True) \\\n",
    "            .option('inferSchema', True) \\\n",
    "            .csv('data/flights_small.csv')\n",
    "\n",
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab65bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4404091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(flights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a36b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert from Spark df to pandas df\n",
    "flights_pd = flights_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce6f015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>flight</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>658</td>\n",
       "      <td>-7</td>\n",
       "      <td>935</td>\n",
       "      <td>-5</td>\n",
       "      <td>VX</td>\n",
       "      <td>N846VA</td>\n",
       "      <td>1780</td>\n",
       "      <td>SEA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>132</td>\n",
       "      <td>954</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1040</td>\n",
       "      <td>5</td>\n",
       "      <td>1505</td>\n",
       "      <td>5</td>\n",
       "      <td>AS</td>\n",
       "      <td>N559AS</td>\n",
       "      <td>851</td>\n",
       "      <td>SEA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>360</td>\n",
       "      <td>2677</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1443</td>\n",
       "      <td>-2</td>\n",
       "      <td>1652</td>\n",
       "      <td>2</td>\n",
       "      <td>VX</td>\n",
       "      <td>N847VA</td>\n",
       "      <td>755</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>111</td>\n",
       "      <td>679</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1705</td>\n",
       "      <td>45</td>\n",
       "      <td>1839</td>\n",
       "      <td>34</td>\n",
       "      <td>WN</td>\n",
       "      <td>N360SW</td>\n",
       "      <td>344</td>\n",
       "      <td>PDX</td>\n",
       "      <td>SJC</td>\n",
       "      <td>83</td>\n",
       "      <td>569</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>754</td>\n",
       "      <td>-1</td>\n",
       "      <td>1015</td>\n",
       "      <td>1</td>\n",
       "      <td>AS</td>\n",
       "      <td>N612AS</td>\n",
       "      <td>522</td>\n",
       "      <td>SEA</td>\n",
       "      <td>BUR</td>\n",
       "      <td>127</td>\n",
       "      <td>937</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day dep_time dep_delay arr_time arr_delay carrier tailnum  \\\n",
       "0  2014     12    8      658        -7      935        -5      VX  N846VA   \n",
       "1  2014      1   22     1040         5     1505         5      AS  N559AS   \n",
       "2  2014      3    9     1443        -2     1652         2      VX  N847VA   \n",
       "3  2014      4    9     1705        45     1839        34      WN  N360SW   \n",
       "4  2014      3    9      754        -1     1015         1      AS  N612AS   \n",
       "\n",
       "   flight origin dest air_time  distance hour minute  \n",
       "0    1780    SEA  LAX      132       954    6     58  \n",
       "1     851    SEA  HNL      360      2677   10     40  \n",
       "2     755    SEA  SFO      111       679   14     43  \n",
       "3     344    PDX  SJC       83       569   17      5  \n",
       "4     522    SEA  BUR      127       937    7     54  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4f4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(flights_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dc5e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert Pandas table back to Spark \n",
    "# Spark's createDataFrame method creates an object that is stored locally, but not in SparkSession catalog\n",
    "spark_temp_df = spark.createDataFrame(flights_pd)\n",
    "type(spark_temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a474c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/13 21:53:30 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/05/13 21:53:30 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/05/13 21:53:32 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "22/05/13 21:53:32 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore nm@192.168.1.143\n",
      "22/05/13 21:53:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='flights', database='default', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='flights_df_tbl', database='default', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Since the newly created Spark df object is stored locally, it cannot be found in other contexts such as SQL\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e91ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='flights', database='default', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='flights_df_tbl', database='default', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='temp_tbl', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# To access the new spark df in different contexts, we need to save it as a temporary table\n",
    "# using createTempView() which can duplicate tables, or createOrReplaceTempView() which avoids duplicates\n",
    "# Now the table is available in this current SparkSession as a temporary table\n",
    "spark_temp_df.createOrReplaceTempView(\"temp_tbl\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spark]",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
